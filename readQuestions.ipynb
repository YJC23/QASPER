{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2c3f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached dataset qasper (/Users/albertomancarella/.cache/huggingface/datasets/allenai___qasper/qasper/0.3.0/2bfcd239e581ab83f9ab7b76a82e42c6bcf574a13246ae6cc5a6c357c35f96f9)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 315.76it/s]\n",
      "Article 80 no evidence.\n",
      "Article 160 no evidence.\n",
      "Article 165 no evidence.\n",
      "Article 168 no evidence.\n",
      "Article 209 no evidence.\n",
      "Article 217 no evidence.\n",
      "Article 255 no evidence.\n",
      "Article 256 no evidence.\n",
      "Article 265 no evidence.\n",
      "Article 279 no evidence.\n",
      "Article 297 no evidence.\n",
      "Article 318 no evidence.\n",
      "Article 323 no evidence.\n",
      "Article 344 no evidence.\n",
      "Article 366 no evidence.\n",
      "Article 367 no evidence.\n",
      "Article 393 no evidence.\n",
      "Article 405 no evidence.\n",
      "Article 428 no evidence.\n",
      "Article 450 no evidence.\n",
      "Article 457 no evidence.\n",
      "Article 461 no evidence.\n",
      "Article 489 no evidence.\n",
      "Article 495 no evidence.\n",
      "Article 497 no evidence.\n",
      "Article 500 no evidence.\n",
      "Article 511 no evidence.\n",
      "Article 527 no evidence.\n",
      "Article 530 no evidence.\n",
      "Article 531 no evidence.\n",
      "Article 534 no evidence.\n",
      "Article 558 no evidence.\n",
      "Article 559 no evidence.\n",
      "Article 560 no evidence.\n",
      "Article 576 no evidence.\n",
      "Article 594 no evidence.\n",
      "Article 603 no evidence.\n",
      "Article 605 no evidence.\n",
      "Article 638 no evidence.\n",
      "Article 650 no evidence.\n",
      "Article 652 no evidence.\n",
      "Article 669 no evidence.\n",
      "Article 673 no evidence.\n",
      "Article 674 no evidence.\n",
      "Article 687 no evidence.\n",
      "Article 702 no evidence.\n",
      "Article 703 no evidence.\n",
      "Article 707 no evidence.\n",
      "Article 714 no evidence.\n",
      "Article 733 no evidence.\n",
      "Article 739 no evidence.\n",
      "Article 742 no evidence.\n",
      "Article 749 no evidence.\n",
      "Article 759 no evidence.\n",
      "Article 760 no evidence.\n",
      "Article 763 no evidence.\n",
      "Article 764 no evidence.\n",
      "Article 766 no evidence.\n",
      "Article 777 no evidence.\n",
      "Article 779 no evidence.\n",
      "Article 782 no evidence.\n",
      "Article 794 no evidence.\n",
      "Article 822 no evidence.\n",
      "Article 827 no evidence.\n",
      "Article 836 no evidence.\n",
      "Article 848 no evidence.\n",
      "Article 853 no evidence.\n",
      "Article 856 no evidence.\n",
      "Article 859 no evidence.\n",
      "Article 868 no evidence.\n",
      "Article 869 no evidence.\n",
      "Article 872 no evidence.\n",
      "Article 874 no evidence.\n",
      "Article 881 no evidence.\n",
      "Article 882 no evidence.\n",
      "Data exported to getExperiment.json\n"
     ]
    }
   ],
   "source": [
    "# !python3 experiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6f4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Open the JSON file\n",
    "with open('getExperiment.json') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84031836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readQandA(i, response):\n",
    "    print(f\"Article {i}\")\n",
    "    curArticle = data[i]\n",
    "    for eachQuestion in curArticle[\"qas\"]:\n",
    "        print(eachQuestion[\"question\"])\n",
    "        evidence = eachQuestion[\"evidence\"]\n",
    "        if response == True:\n",
    "            for eachEvidence in evidence:\n",
    "                \n",
    "                print(f\"({(eachEvidence)}) {curArticle['passages'][eachEvidence]}\")\n",
    "        if response:\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0635cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(i):\n",
    "    with open(f\"article{i}.txt\", \"w\") as file:\n",
    "        for i, element in enumerate(data[i][\"passages\"]):\n",
    "            # Add indentation before each element\n",
    "            output_string = f\"({i}) \" + str(element) + \"\\n\"\n",
    "            file.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2b96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listQuestions(n):\n",
    "    for each in range(n):\n",
    "        readQandA(each, False)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99285fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95499306",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m listQuestions(\u001b[39mlen\u001b[39;49m(data))\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mlistQuestions\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlistQuestions\u001b[39m(n):\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m each \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m----> 3\u001b[0m         readQandA(each, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m, in \u001b[0;36mreadQandA\u001b[0;34m(i, response)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadQandA\u001b[39m(i, response):\n\u001b[1;32m      2\u001b[0m     curArticle \u001b[39m=\u001b[39m data[i]\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mArticle \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mcurArticle[\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m eachQuestion \u001b[39min\u001b[39;00m curArticle[\u001b[39m\"\u001b[39m\u001b[39mqas\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m      6\u001b[0m         \u001b[39mprint\u001b[39m(eachQuestion[\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "listQuestions(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b7a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 249\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda71b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 249\n",
      "Which are the four Arabic dialects?\n",
      "(7) For the MGB-3 ADI task, the challenge organizers provided 13,825 utterances (53.6 hours) for the training (TRN) set, 1,524 utterances (10 hours) for a development (DEV) set, and 1,492 utterances (10.1 hours) for a test (TST) set. Each dataset consisted of five Arabic dialects: Egyptian (EGY), Levantine (LEV), Gulf (GLF), North African (NOR), and Modern Standard Arabic (MSA). Detailed statistics of the ADI dataset can be found in BIBREF23 . Table TABREF3 shows some facts about the evaluation conditions and data properties. Note that the development set is relatively small compared to the training set. However, it is matched with the test set channel domain. Thus, the development set provides valuable information to adapt or compensate the channel (recording) domain mismatch between the train and test sets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first input represents article index\n",
    "# second input represents if to include response for each question\n",
    "readQandA(i, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5de51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
